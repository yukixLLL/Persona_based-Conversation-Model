{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "ENC_HIDDEN_SIZE = 512\n",
    "DEC_HIDDEN_SIZE = 512\n",
    "NUM_LAYER = 4\n",
    "DROP_OUT = 0.2\n",
    "embedding_dim = 512\n",
    "speaker_dim = 128\n",
    "MAXLEN = 50\n",
    "speakerNum = 14\n",
    "EPOCHS = 10\n",
    "LATENT_SIZE = 200\n",
    "# KEEP_PROB = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH + 'tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "d_tensor_train = np.load(PATH + 'd_tensor_train.npy',allow_pickle=True)\n",
    "r_tensor_train = np.load(PATH + 'r_tensor_train.npy',allow_pickle=True)\n",
    "\n",
    "dia_train = [t[0] for t in d_tensor_train]\n",
    "aid_train = [t[1] for t in d_tensor_train]\n",
    "res_train = [t[0] for t in r_tensor_train]\n",
    "sid_train = [t[1] for t in r_tensor_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dia_train = dia_train[:32]\n",
    "sample_aid_train = aid_train[:32]\n",
    "sample_res_train = res_train[:32]\n",
    "sample_sid_train = sid_train[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(d_tensor_train[:32])\n",
    "steps_per_epoch = int(np.ceil(len(d_tensor_train[:32]) / BATCH_SIZE ))\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dataset done.\n"
     ]
    }
   ],
   "source": [
    "# create tf.dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((dia_train, res_train, sid_train, aid_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "print(\"Create dataset done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word_Embedding(tf.keras.Model):\n",
    "    def __init__(self,vocab_size,embedding_dim):\n",
    "        super(Word_Embedding, self).__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "    def call(self,x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Encoder (Bidirectional LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, vocab_size, batch_size=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.fw_layer = tf.keras.layers.LSTM(self.hidden_size,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.bw_layer = tf.keras.layers.LSTM(self.hidden_size,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       go_backwards=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.bi_rnn = tf.keras.layers.Bidirectional(self.fw_layer, merge_mode='concat', backward_layer=self.bw_layer)\n",
    "    def call(self, d):\n",
    "        output,fw_hidden,fw_c,bw_hidden,bw_c = self.bi_rnn(d)\n",
    "        hidden = tf.concat([fw_hidden,bw_hidden],1)\n",
    "        c = tf.concat([fw_c,bw_c],1)\n",
    "        return output, hidden,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input, example_target,example_sid, example_aid = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 50])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = Word_Embedding(vocab_size,embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder hidden state.shape:(16, 1024)\n",
      "encoder cell state.shape:(16, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(ENC_HIDDEN_SIZE, vocab_size, BATCH_SIZE)\n",
    "# enc_hidden = encoder.initialize_hidden_state(BATCH_SIZE)\n",
    "inp_emb = word_embedding(example_input)\n",
    "enc_output,enc_hidden,enc_c = encoder(inp_emb)\n",
    "print(\"encoder hidden state.shape:{}\".format(enc_hidden.shape))\n",
    "print(\"encoder cell state.shape:{}\".format(enc_c.shape))\n",
    "targ_emb = word_embedding(example_target)\n",
    "_,targ_hidden,_ = encoder(targ_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 512])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ_emb[:,1,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gaussian(mu, logvar):\n",
    "    epsilon = tf.random.normal(logvar.shape)\n",
    "    std = tf.exp(0.5 * logvar)\n",
    "    z= mu + tf.multiply(std, epsilon)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recognition_Network(tf.keras.Model):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Recognition_Network, self).__init__()\n",
    "        self.rec_nn = tf.keras.layers.Dense(latent_size*2)\n",
    "    \n",
    "    def call(self,enc_hidden,targ_hidden):\n",
    "#         print(enc_hidden.shape)\n",
    "        recog_input = tf.concat([enc_hidden,targ_hidden],1)\n",
    "        recog_mulogvar = self.rec_nn(recog_input)\n",
    "#         print(\"recog_mulogvar.shape:{}\".format(recog_mulogvar.shape))\n",
    "        recog_mu,recog_logvar = tf.split(recog_mulogvar,2,axis=1)\n",
    "        return recog_mu,recog_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_network = Recognition_Network(LATENT_SIZE)\n",
    "recog_mu,recog_logvar = recognition_network(enc_hidden, targ_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior_Network(tf.keras.Model):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Prior_Network, self).__init__()\n",
    "        self.fc = tf.keras.layers.Dense(max(latent_size*2,100))\n",
    "        self.pri_nn = tf.keras.layers.Dense(latent_size*2)\n",
    "    \n",
    "    def call(self,enc_hidden):\n",
    "#         print(enc_hidden.shape)\n",
    "        prior_fc1 = self.fc(enc_hidden)\n",
    "#         print(prior_fc1.shape)\n",
    "        prior_mulogvar = self.pri_nn(prior_fc1)\n",
    "#         print(prior_mulogvar.shape)\n",
    "        prior_mu,prior_logvar = tf.split(prior_mulogvar,2,axis=1)\n",
    "        return prior_mu,prior_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_network = Prior_Network(LATENT_SIZE)\n",
    "prior_mu,prior_logvar = prior_network(enc_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_prior = False ##seem to use prior for test dataset?\n",
    "latent_sample = tf.cond(use_prior,lambda:sample_gaussian(prior_mu,prior_logvar),\n",
    "                       lambda:sample_gaussian(recog_mu,recog_logvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 200])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generation_Network(tf.keras.Model):\n",
    "    def __init__(self, vocab_size,hidden_size):\n",
    "        super(Generation_Network, self).__init__()\n",
    "        self.bow_fc = tf.keras.layers.Dense(400)\n",
    "        self.bow_logits = tf.keras.layers.Dense(vocab_size)\n",
    "        self.init_fc = tf.keras.layers.Dense(hidden_size)\n",
    "    \n",
    "    def call(self,enc_hidden,latent_sample):\n",
    "        gen_inputs = tf.concat([enc_hidden,latent_sample],1)\n",
    "        bow_fc1 = self.bow_fc(gen_inputs)\n",
    "#         if KEEP_PROB < 1.0:\n",
    "#             bow_fc1 = tf.nn.dropout(bow_fc1,KEEP_PROB)\n",
    "        bow_logit = self.bow_logits(bow_fc1)\n",
    "#         print(\"bow_logit.shape:{}\".format(bow_logit.shape))\n",
    "        dec_init_state = self.init_fc(gen_inputs)\n",
    "#         print(\"dec_init_state.shape:{}\".format(dec_init_state.shape))\n",
    "        # return decoder initial state and bag of word loss\n",
    "        # we use lstm in decoder\n",
    "        return [dec_init_state,dec_init_state],bow_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_network = Generation_Network(vocab_size,DEC_HIDDEN_SIZE)\n",
    "dec_init_state, bow_logit = generation_network(enc_hidden,latent_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder (old one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_Feed(tf.keras.Model):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention_Feed, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(hidden_size)\n",
    "        self.W2 = tf.keras.layers.Dense(hidden_size)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1024)\n"
     ]
    }
   ],
   "source": [
    "attention = Attention_Feed(DEC_HIDDEN_SIZE)\n",
    "context_vector, attention_weights = attention(enc_hidden, enc_output)\n",
    "print(context_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, vocab_size, speaker_dim, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        #         self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.speaker_embedding = tf.keras.layers.Embedding(speakerNum, speaker_dim)\n",
    "        #         self.input_size = embedding_dim\n",
    "        self.output_size = vocab_size  # vocabulary size\n",
    "        self.lstm_1 = tf.keras.layers.LSTM(self.hidden_size,\n",
    "                                           return_sequences=True,\n",
    "                                           return_state=True,\n",
    "                                           dropout=DROP_OUT,\n",
    "                                           recurrent_initializer='glorot_uniform')\n",
    "        self.lstms = []\n",
    "        for k in range(self.num_layers - 1):\n",
    "            self.lstms.append(tf.keras.layers.LSTM(self.hidden_size,\n",
    "                                                   return_sequences=True,\n",
    "                                                   return_state=True,\n",
    "                                                   dropout=DROP_OUT))\n",
    "        self.fc = tf.keras.layers.Dense(self.output_size)\n",
    "        self.W1 = tf.keras.layers.Dense(speaker_dim)\n",
    "        self.W2 = tf.keras.layers.Dense(speaker_dim)\n",
    "        # attention feed on context\n",
    "        self.attention = Attention_Feed(self.hidden_size)\n",
    "\n",
    "    def call(self, target, enc_output, init_state, speaker_id, addressee_id=None):\n",
    "        hidden = init_state[0]\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        # personas\n",
    "        speaker = self.speaker_embedding(speaker_id)\n",
    "\n",
    "        if addressee_id is not None:\n",
    "            addressee = self.speaker_embedding(addressee_id)\n",
    "            v_ij = self.combine_user_vector(speaker, addressee)\n",
    "            features = tf.concat([target, tf.expand_dims(v_ij, 1)], axis=-1)\n",
    "        else:\n",
    "            features = tf.concat([target, tf.expand_dims(speaker, 1)], axis=-1)\n",
    "        r = tf.concat([tf.expand_dims(context_vector, 1), features], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the 4-layer LSTM\n",
    "        output, hidden, c = self.lstm_1(r, initial_state=init_state)\n",
    "        init_state = [hidden, c]\n",
    "        for k in range(self.num_layers - 1):\n",
    "            #             print(\"output.shape: {}\".format(output.shape))\n",
    "            output, state, c = self.lstms[k](output, initial_state=init_state)\n",
    "            init_state = [hidden, c]\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        # log_softmax used before\n",
    "        output = tf.nn.log_softmax(self.fc(output), axis=1)\n",
    "        return output, state, c, attention_weights\n",
    "\n",
    "    def combine_user_vector(self,i_em, j_em):\n",
    "        V_ij = tf.nn.tanh(self.W1(i_em) + self.W2(j_em))\n",
    "        return V_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_init_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(DEC_HIDDEN_SIZE,vocab_size,speaker_dim,4)\n",
    "targ = word_embedding(tf.expand_dims([tokenizer.word_index['<sos>']]*BATCH_SIZE,1))\n",
    "output, state,_,_ = decoder(targ,enc_output,dec_init_state,example_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 26028])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_real_word(real):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "#     pdb.set_trace()\n",
    "    word_per_line = tf.math.reduce_sum(mask,1)\n",
    "    return word_per_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_loss_function(reals,bow_logit):\n",
    "    # if I need to adjust according to the lenght of sentence???\n",
    "    labels = reals[:,1:]\n",
    "    mask = tf.math.logical_not(tf.math.equal(labels, 0))\n",
    "    \n",
    "    bow_logit_tile = tf.tile(tf.expand_dims(bow_logit,1),[1,MAXLEN-1,1])\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels,bow_logit_tile) \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "#     print(\"bow_loss.shape before reduction:{}\".format(loss_.shape))\n",
    "    bow_loss = tf.reduce_sum(loss_*mask,axis = 1)\n",
    "#     print(\"bow_loss.shape after reduction:{}\".format(bow_loss.shape))\n",
    "    return tf.reduce_mean(bow_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(136.69319, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "avg_bow_loss = bow_loss_function(example_target,bow_logit)\n",
    "print(avg_bow_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_loss_function(real, pred,word_per_line):\n",
    "    # loss of every word\n",
    "    # true word mask\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ = loss_ * mask\n",
    "    return tf.math.reduce_sum(loss_/word_per_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rc_loss:17.32868003845215\n"
     ]
    }
   ],
   "source": [
    "word_per_line = count_real_word(example_target)\n",
    "rc_loss = rc_loss_function(example_target[:,1], output,word_per_line)\n",
    "print(\"rc_loss:{}\".format(rc_loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "isAnnealing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(avg_rc_loss,avg_bow_loss,recog_mu,recog_logvar,prior_mu,prior_logvar,global_iter,kl_full_step):\n",
    "    temp = 1 + (recog_logvar - prior_logvar) - tf.math.divide(tf.pow(prior_mu - recog_mu,2),tf.exp(prior_logvar))-tf.math.divide(tf.exp(recog_logvar),tf.exp(prior_logvar))\n",
    "    kld = -1/2 * tf.reduce_sum(temp,axis = 1)\n",
    "    avg_kld = tf.reduce_mean(kld)\n",
    "    kl_weight = tf.minimum(tf.cast(global_iter/kl_full_step,dtype=tf.float32),1.0)\n",
    "    \n",
    "    elbo = avg_rc_loss + kl_weight * avg_kld\n",
    "    aug_elbo = avg_bow_loss + elbo\n",
    "    \n",
    "    return elbo,aug_elbo,avg_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO:17.328733444213867\n",
      "Augmented elbo:154.0219268798828\n",
      "Kl divergence:0.10809069126844406\n"
     ]
    }
   ],
   "source": [
    "elbo,aug_elbo,avg_kld = loss_function(rc_loss,avg_bow_loss,recog_mu,recog_logvar,prior_mu,prior_logvar,1,2000)\n",
    "print(\"ELBO:{}\".format(elbo))\n",
    "print(\"Augmented elbo:{}\".format(aug_elbo))\n",
    "print(\"Kl divergence:{}\".format(avg_kld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train(object):\n",
    "    def __init__(self,word_embedding,encoder,decoder,recognition_network,prior_network,generation_network,optimizer,tokenizer):\n",
    "        self.word_embedding = word_embedding\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.recognition_network  = recognition_network\n",
    "        self.prior_network = prior_network\n",
    "        self.generation_network = generation_network\n",
    "        self.tokenizer = tokenizer\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "#     @tf.function\n",
    "    def train_step(self,inp, targ,global_iter,kl_full_step,speaker_id,batch_size=BATCH_SIZE, addressee_id=None):\n",
    "        rc_avg_loss = 0\n",
    "        word_per_line = count_real_word(targ)\n",
    "        with tf.GradientTape() as tape:\n",
    "            inp_emb = self.word_embedding(inp)\n",
    "            targ_emb = self.word_embedding(targ)\n",
    "            enc_output,enc_hidden,enc_c = self.encoder(inp_emb)\n",
    "            _,targ_hidden,_ = self.encoder(targ_emb)\n",
    "            # VAE module\n",
    "            prior_mu,prior_logvar = self.prior_network(enc_hidden)\n",
    "            recog_mu,recog_logvar = self.recognition_network(enc_hidden,targ_hidden)\n",
    "            \n",
    "            latent_sample = tf.cond(use_prior,lambda:sample_gaussian(prior_mu,prior_logvar),\n",
    "                       lambda:sample_gaussian(recog_mu,recog_logvar))\n",
    "            dec_init_state,bow_logit = self.generation_network(enc_hidden,latent_sample)\n",
    "            \n",
    "#             dec_input = self.word_embedding(tf.expand_dims([self.tokenizer.word_index['<sos>']]*batch_size,1))\n",
    "            dec_input = tf.expand_dims(targ_emb[:,0,:],1)\n",
    "            \n",
    "            rc_loss = 0\n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                if addressee_id is not None:\n",
    "                    predictions, dec_hidden,dec_c, _ = self.decoder(\n",
    "                        dec_input,enc_output, dec_init_state,speaker_id,addressee_id)\n",
    "                else:\n",
    "                    predictions, dec_hidden, dec_c,_ = self.decoder(\n",
    "                        dec_input,enc_output, dec_init_state,speaker_id)\n",
    "                dec_init_state = [dec_hidden,dec_c]\n",
    "                rc_loss += rc_loss_function(targ[:, t], predictions, word_per_line)\n",
    "                \n",
    "                # using teacher forcing\n",
    "#                 dec_input = self.word_embedding(tf.expand_dims(targ[:, t], 1))\n",
    "                dec_input = tf.expand_dims(targ_emb[:,t,:],1)\n",
    "            \n",
    "            avg_rc_loss = (rc_loss / int(targ.shape[0]))\n",
    "            avg_bow_loss = bow_loss_function(targ,bow_logit)\n",
    "            elbo,aug_elbo,kl_loss = loss_function(avg_rc_loss,avg_bow_loss,recog_mu,recog_logvar,prior_mu,prior_logvar,global_iter,kl_full_step)\n",
    "            variables = self.encoder.trainable_variables+ self.decoder.trainable_variables + self.recognition_network.trainable_variables+ self.prior_network.trainable_variables+ self.generation_network.trainable_variables\n",
    "            gradients = tape.gradient(aug_elbo, variables)\n",
    "            self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "            return elbo,avg_bow_loss,avg_rc_loss,kl_loss\n",
    "\n",
    "    def run_iter(self,epochs,isAddressee,steps_per_epoch,dataset,checkpoint,checkpoint_prefix):\n",
    "        global_iter = 0\n",
    "        kl_full_step = steps_per_epoch * epochs / 2\n",
    "        for e in range(epochs):\n",
    "            start = time.time()\n",
    "            elbo_losses = 0\n",
    "            bow_losses = 0\n",
    "            rc_losses = 0\n",
    "            kl_losses = 0\n",
    "            for (batch, (inp, targ,sid,aid)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "                batch_sz =targ.shape[0]\n",
    "                if isAddressee==True:\n",
    "                    # global iter to count iter\n",
    "                    elbo,avg_bow_loss,avg_rc_loss,kl_loss = self.train_step(inp, targ,global_iter,kl_full_step,sid,batch_sz,aid)\n",
    "                else:\n",
    "                    # global iter to count iter\n",
    "                    elbo,avg_bow_loss,avg_rc_loss,kl_loss = self.train_step(inp, targ,global_iter,kl_full_step,sid,batch_sz)\n",
    "                elbo_losses += elbo\n",
    "                bow_losses += avg_bow_loss\n",
    "                rc_losses += avg_rc_loss\n",
    "                kl_losses += kl_loss\n",
    "                global_iter += 1\n",
    "                if batch % 100 == 0:\n",
    "                    print('Epoch {} Batch {} ELBO {:.4f} BOW LOSS {:.4f} RC LOSS {:.4f} KL LOSS {:.4f}'.format(e + 1,\n",
    "                                                                 batch,\n",
    "                                                                 elbo.numpy(),avg_bow_loss.numpy(),\n",
    "                                                                 avg_rc_loss.numpy(),kl_loss.numpy()))\n",
    "            \n",
    "            # saving (checkpoint) the model every 2 epochs\n",
    "            if (e + 1) % 2 == 0:\n",
    "                checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "            print('Epoch {} ELBO {:.4f} BOW LOSS {:.4f} RC LOSS {:.4f}'.format(e + 1,\n",
    "                                              elbo_losses / steps_per_epoch,\n",
    "                                              bow_losses / steps_per_epoch,\n",
    "                                              rc_losses / steps_per_epoch,\n",
    "                                              kl_losses / steps_per_epoch))\n",
    "            print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start)) \n",
    "    \n",
    "    def run_iter_test(self, epochs, isAddressee, steps_per_epoch, dataset):\n",
    "        global_iter = 0\n",
    "        kl_full_step = steps_per_epoch * epochs / 2\n",
    "        for e in range(epochs):\n",
    "            start = time.time()\n",
    "            elbo_losses = 0\n",
    "            bow_losses = 0\n",
    "            rc_losses = 0\n",
    "            kl_losses = 0\n",
    "            for (batch, (inp, targ,sid,aid)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "                batch_sz =targ.shape[0]\n",
    "                print(\"batch size:{}\".format(batch_sz))\n",
    "                if isAddressee==True:\n",
    "                    # global iter to count iter\n",
    "                    elbo,avg_bow_loss,avg_rc_loss,kl_loss = self.train_step(inp, targ,global_iter,kl_full_step,sid,batch_sz,aid)\n",
    "                else:\n",
    "                    # global iter to count iter\n",
    "                    elbo,avg_bow_loss,avg_rc_loss,kl_loss = self.train_step(inp, targ,global_iter,kl_full_step,sid,batch_sz)\n",
    "                elbo_losses += elbo\n",
    "                bow_losses += avg_bow_loss\n",
    "                rc_losses += avg_rc_loss\n",
    "                kl_losses += kl_loss\n",
    "                global_iter += 1\n",
    "\n",
    "                print('Epoch {} Batch {} ELBO {:.4f} BOW LOSS {:.4f} RC LOSS {:.4f} KL LOSS {:.4f}'.format(e + 1,\n",
    "                                                                 batch,elbo.numpy(),avg_bow_loss.numpy(),\n",
    "                                                                 avg_rc_loss.numpy(),kl_loss.numpy()))\n",
    "\n",
    "\n",
    "            print('Epoch {} ELBO {:.4f} BOW LOSS {:.4f} RC LOSS {:.4f}'.format(e + 1,\n",
    "                                              elbo_losses / steps_per_epoch,\n",
    "                                              bow_losses / steps_per_epoch,\n",
    "                                              rc_losses / steps_per_epoch,\n",
    "                                              kl_losses / steps_per_epoch))\n",
    "            print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = Word_Embedding(vocab_size,embedding_dim)\n",
    "encoder = Encoder(ENC_HIDDEN_SIZE, vocab_size, BATCH_SIZE)\n",
    "decoder = Decoder(DEC_HIDDEN_SIZE,vocab_size,speaker_dim,4)\n",
    "recognition_network = Recognition_Network(LATENT_SIZE)\n",
    "prior_network = Prior_Network(LATENT_SIZE)\n",
    "generation_network = Generation_Network(vocab_size,DEC_HIDDEN_SIZE)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nn = Train(word_embedding,encoder,decoder,recognition_network,prior_network,generation_network,optimizer,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbo,avg_bow_loss,avg_rc_loss,kl_loss = train_nn.train_step(example_input, example_target,1,2000,example_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:16\n",
      "Epoch 1 Batch 0 ELBO 4.0693 BOW LOSS 77.5264 RC LOSS 4.0693 KL LOSS 4.4133\n",
      "batch size:16\n",
      "Epoch 1 Batch 1 ELBO 6.4102 BOW LOSS 44.3939 RC LOSS 3.8987 KL LOSS 7.5344\n",
      "Epoch 1 ELBO 5.2397 BOW LOSS 60.9601 RC LOSS 3.9840\n",
      "Time taken for 1 epoch 22.433491945266724 sec\n",
      "\n",
      "batch size:16\n",
      "Epoch 2 Batch 0 ELBO 9.9989 BOW LOSS 46.5391 RC LOSS 3.8640 KL LOSS 9.2024\n",
      "batch size:16\n",
      "Epoch 2 Batch 1 ELBO 11.6055 BOW LOSS 83.9159 RC LOSS 4.2512 KL LOSS 7.3543\n",
      "Epoch 2 ELBO 10.8022 BOW LOSS 65.2275 RC LOSS 4.0576\n",
      "Time taken for 1 epoch 22.074671983718872 sec\n",
      "\n",
      "batch size:16\n",
      "Epoch 3 Batch 0 ELBO 8.5056 BOW LOSS 73.6567 RC LOSS 4.1440 KL LOSS 4.3617\n",
      "batch size:16\n",
      "Epoch 3 Batch 1 ELBO 7.1713 BOW LOSS 95.5927 RC LOSS 4.5393 KL LOSS 2.6320\n",
      "Epoch 3 ELBO 7.8384 BOW LOSS 84.6247 RC LOSS 4.3416\n",
      "Time taken for 1 epoch 22.195114135742188 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_nn.run_iter_test(3,False,steps_per_epoch,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
