{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from util import *\n",
    "from encoder import * \n",
    "from decoder import *\n",
    "from train import *\n",
    "from word_embedding import *\n",
    "from recognition_nw import *\n",
    "from prior_nw import *\n",
    "from generation_nw import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tensor_test = np.load(PATH + 'd_tensor_test.npy',allow_pickle=True)\n",
    "r_tensor_test = np.load(PATH + 'r_tensor_test.npy',allow_pickle=True)\n",
    "dia_test = [t[0] for t in d_tensor_test]\n",
    "aid_test = [t[1] for t in d_tensor_test]\n",
    "res_test = [t[0] for t in r_tensor_test]\n",
    "sid_test = [t[1] for t in r_tensor_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH + 'tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "ENC_HIDDEN_SIZE = 300\n",
    "DEC_HIDDEN_SIZE = 512\n",
    "NUM_LAYER = 4\n",
    "DROP_OUT = 0.2\n",
    "embedding_dim = 512\n",
    "speaker_dim = 128\n",
    "MAXLEN = 50\n",
    "speakerNum = 14\n",
    "EPOCHS = 10\n",
    "LATENT_SIZE = 200\n",
    "Use_Prior = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response with beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../vae_ckpt_SM_300e_512d_200l/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.training.tracking.util.CheckpointLoadStatus object at 0xb2cb672b0>\n"
     ]
    }
   ],
   "source": [
    "word_embedding = Word_Embedding(vocab_size, embedding_dim)\n",
    "encoder = Encoder(ENC_HIDDEN_SIZE, vocab_size, BATCH_SIZE)\n",
    "decoder = Decoder(DEC_HIDDEN_SIZE, vocab_size, speaker_dim, NUM_LAYER)\n",
    "recognition_network = Recognition_Network(LATENT_SIZE)\n",
    "prior_network = Prior_Network(LATENT_SIZE)\n",
    "generation_network = Generation_Network(vocab_size, DEC_HIDDEN_SIZE)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "cp = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                             word_embedding=word_embedding,\n",
    "                             encoder=encoder,\n",
    "                             decoder=decoder,\n",
    "                             recognition_network=recognition_network,\n",
    "                             prior_network=prior_network,\n",
    "                             generation_network=generation_network)\n",
    "status = cp.restore(checkpoint_dir + \"speaker-ckpt-4\")\n",
    "print(status)\n",
    "train_nn = Train(word_embedding, encoder, decoder, recognition_network, prior_network, generation_network,optimizer,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_word(response_sentence,tokenizer):\n",
    "    sentence = list()\n",
    "    for idx in response_sentence:\n",
    "        sentence.append(tokenizer.index_word[idx])\n",
    "        if(tokenizer.index_word[idx]=='<eos>'):\n",
    "            break;\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<sos> ' + w + ' <eos>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver_to_tensor(sentence,tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=MAXLEN,\n",
    "                                                         padding='post')\n",
    "    tensor = tf.convert_to_tensor(inputs,dtype=np.int32)\n",
    "    return tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(train_nn,inp,speaker_id,addressee_id=None,max_len = MAXLEN,beam_size = 2):\n",
    "    generate_size = beam_size\n",
    "    inputs = np.expand_dims(inp, axis=0)\n",
    "    s_id = np.expand_dims(speaker_id, axis=0)\n",
    "    if addressee_id is not None:\n",
    "        a_id = np.expand_dims(addressee_id, axis=0)\n",
    "    inp_emb = train_nn.word_embedding(inputs)\n",
    "    enc_out, enc_hidden,enc_c = train_nn.encoder(inp_emb)\n",
    "    prior_mu, prior_logvar = train_nn.prior_network(enc_hidden)\n",
    "    \n",
    "    latent_sample = sample_gaussian(prior_mu, prior_logvar)\n",
    "    dec_init_state, _ = train_nn.generation_network(enc_hidden, latent_sample)\n",
    "    dec_input = train_nn.word_embedding(tf.convert_to_tensor([train_nn.tokenizer.word_index['<sos>']]))\n",
    "#     print(dec_input)\n",
    "    dec_input = tf.expand_dims(dec_input,0)\n",
    "#     print(dec_input.shape)\n",
    "    sos = train_nn.tokenizer.word_index['<sos>']\n",
    "    \n",
    "    if addressee_id is not None:\n",
    "        predictions, dec_hidden, dec_c,_ = train_nn.decoder(dec_input,enc_out, dec_init_state,s_id,a_id)\n",
    "    else:\n",
    "        predictions, dec_hidden, dec_c,_ = train_nn.decoder(dec_input,enc_out, dec_init_state,s_id)\n",
    "\n",
    "    dec_init_state = [dec_hidden,dec_c]\n",
    "    pred_prob,pred_top_k = tf.math.top_k(predictions,k=beam_size)\n",
    "#     for i in range(pred_prob[0].shape[0]):\n",
    "#         print(\"prob:{},word:{}\".format(pred_prob[0][i],tokenizer.index_word[pred_top_k[0][i].numpy()]))\n",
    "    # beam: (prob,sentence,dec_inp,dec_init,isEnd)\n",
    "    finished = list() # to store finished sentence\n",
    "    beam = list()\n",
    "    for ind, i in enumerate(pred_top_k[0]):\n",
    "        word_idx = i.numpy()\n",
    "        if tokenizer.index_word[word_idx]=='<eos>':\n",
    "            finished.append([pred_prob[0][ind],[sos]+[word_idx]])\n",
    "        i_emb = train_nn.word_embedding(tf.expand_dims(i,0))\n",
    "#         print(i_emb.shape)\n",
    "        beam.append([pred_prob[0][ind],[sos]+[i.numpy()],i_emb,dec_init_state,False])\n",
    "    for t in range(2,max_len):\n",
    "        tmp_beam = list()\n",
    "        for ind,b in enumerate(beam):\n",
    "            if b[-1]:\n",
    "                continue\n",
    "            dec_input = tf.expand_dims(b[2],1)\n",
    "            dec_init_state = b[3]\n",
    "            if addressee_id is not None:\n",
    "                predictions, dec_hidden, dec_c,_ = train_nn.decoder(dec_input,enc_out, dec_init_state,s_id,a_id)\n",
    "            else:\n",
    "                predictions, dec_hidden, dec_c,_ = train_nn.decoder(dec_input,enc_out, dec_init_state,s_id)\n",
    "            \n",
    "            dec_init_state = [dec_hidden,dec_c]\n",
    "\n",
    "            # use beam search to get top k prediction\n",
    "            pred_prob,pred_top_k = tf.math.top_k(predictions,k=beam_size)\n",
    "#             for i in range(pred_prob[0].shape[0]):\n",
    "#                 print(\"beam:{} prob:{},word:{}\".format(ind,pred_prob[0][i],tokenizer.index_word[pred_top_k[0][i].numpy()]))\n",
    "            beam_prob = beam[ind][0]\n",
    "            beam_sen = beam[ind][1]\n",
    "            for ind, i in enumerate(pred_top_k[0]):\n",
    "                isEnd = False\n",
    "                word_idx = i.numpy()\n",
    "                if tokenizer.index_word[word_idx]=='<eos>':\n",
    "                    isEnd = True\n",
    "                i_emb = train_nn.word_embedding(tf.expand_dims(i,0))\n",
    "                tmp_beam.append([(beam_prob + pred_prob[0][ind])/(t+1),beam_sen + [word_idx],i_emb,dec_init_state,isEnd])\n",
    "                \n",
    "        # select top k candidates combination\n",
    "        tmp_beam.sort(key=lambda x:x[0],reverse=True)\n",
    "        tmp_beam = tmp_beam[:generate_size]\n",
    "        beam.clear()\n",
    "        for ind, b in enumerate(tmp_beam):\n",
    "            if b[-1]:\n",
    "                finished.append(b[:2])\n",
    "                generate_size = generate_size - 1\n",
    "            else:\n",
    "                tmp_beam[ind][0] = b[0] * (t+1) # continue to compute probability of whole sentence\n",
    "                beam.append(tmp_beam[ind])\n",
    "                \n",
    "    finished.sort(key=lambda x:x[0],reverse=True)\n",
    "    print(\"{} Finished sentence:\".format(len(finished)))\n",
    "    for i in range(len(finished)):\n",
    "        convert_to_word(finished[i][1],train_nn.tokenizer)\n",
    "#     response_sentence = finished[:beam_size]\n",
    "#     print(\"Response sentence:\")\n",
    "#     for i in range(beam_size):\n",
    "#         convert_to_word(beam[i][1],train_nn.tokenizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> oh . so , how many children do you think we should have ? i m sorry , that was a little abrupt . <eos>\n",
      "<sos> a little . <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> okay , let s go . <eos>\n",
      "<sos> okay , let s just talk about the rest of my life . <eos>\n",
      "<sos> okay , let s just talk about the rest of my business . <eos>\n",
      "addressee:13\n",
      "speaker:6\n"
     ]
    }
   ],
   "source": [
    "convert_to_word(dia_test[idx],tokenizer)\n",
    "convert_to_word(res_test[idx],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx],sid_test[idx],beam_size=3)\n",
    "print(\"addressee:{}\".format(aid_test[idx]))\n",
    "print(\"speaker:{}\".format(sid_test[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> oh . so , how many children do you think we should have ? i m sorry , that was a little abrupt . <eos>\n",
      "<sos> a little . <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> i know . <eos>\n",
      "<sos> i m sorry . what are you doing ? <eos>\n",
      "<sos> i m sorry . <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(7)\n",
    "convert_to_word(dia_test[idx],tokenizer)\n",
    "convert_to_word(res_test[idx],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> oh . so , how many children do you think we should have ? i m sorry , that was a little abrupt . <eos>\n",
      "<sos> a little . <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> yeah , well , i ve been thinking about you guys . <eos>\n",
      "<sos> yeah , well , i ve been thinking about it . <eos>\n",
      "<sos> yeah , well , i ve been thinking about you . <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(8)\n",
    "convert_to_word(dia_test[idx],tokenizer)\n",
    "convert_to_word(res_test[idx],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> oh . so , how many children do you think we should have ? i m sorry , that was a little abrupt . <eos>\n",
      "<sos> a little . <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> what are you doing ? <eos>\n",
      "<sos> what ? <eos>\n",
      "<sos> really ? <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(9)\n",
    "convert_to_word(dia_test[idx],tokenizer)\n",
    "convert_to_word(res_test[idx],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> oh . so , how many children do you think we should have ? i m sorry , that was a little abrupt . <eos>\n",
      "<sos> a little . <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> really ? <eos>\n",
      "<sos> oh , that s so sweet . <eos>\n",
      "<sos> oh , that s great . <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(10)\n",
    "convert_to_word(dia_test[idx],tokenizer)\n",
    "convert_to_word(res_test[idx],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> oh . so , how many children do you think we should have ? i m sorry , that was a little abrupt . <eos>\n",
      "<sos> a little . <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> i thought you liked it . <eos>\n",
      "<sos> you know , i was wondering if you were a kid . <eos>\n",
      "<sos> you know , i was wondering if you were a kid , too . <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(11)\n",
    "convert_to_word(dia_test[idx],tokenizer)\n",
    "convert_to_word(res_test[idx],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2 = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "<sos> you ve spoiled everything ! it s like a nightmare ! my friends and family are out there ! how can i face them ? ! how can you do this to me ? ! <eos>\n",
      "3001\n",
      "<sos> if anyone asks , we ll just say ben addressed them . oh ! so you invited rachel then ? <eos>\n",
      "3002\n",
      "<sos> okay . <eos>\n",
      "3003\n",
      "<sos> what was monica s nickname when she was a field hockey goalie ? <eos>\n",
      "3004\n",
      "<sos> hey , hey . <eos>\n",
      "3005\n",
      "<sos> she does want to . <eos>\n",
      "3006\n",
      "<sos> screw him . you re fine . <eos>\n",
      "3007\n",
      "<sos> all right . leonard went to the office . <eos>\n",
      "3008\n",
      "<sos> oh my god , i can t believe what i m getting ready to say . i wanna have a baby , but i don t wanna have one with someone who doesn t really wanna have one . <eos>\n",
      "3009\n",
      "<sos> so does that answer your question ? <eos>\n",
      "3010\n",
      "<sos> talk to her ? that s all you ve got ? with a cool name like sheldon cooper s council of ladies , i really expected more . give me back the t shirts . <eos>\n",
      "3011\n",
      "<sos> it s her i have to worry about . <eos>\n",
      "3012\n",
      "<sos> fine , i ll put it on facebook like a caveman . <eos>\n",
      "3013\n",
      "<sos> yes it is . see . <eos>\n",
      "3014\n",
      "<sos> hi , dave . uh , it s amy . <eos>\n",
      "3015\n",
      "<sos> anyway , his name is allan and we ve been going out for three years . he was my first client when i became a party planner . he was planning a party for his girlfriend at the time . oh well . and he was theta beta pi\n",
      "3016\n",
      "<sos> whatever . <eos>\n",
      "3017\n",
      "<sos> you did ! oh . . . . i always figured you just thought i was monica s geeky older brother . <eos>\n",
      "3018\n",
      "<sos> well , don t you think it d be healthier if you told him what s going on with you ? <eos>\n",
      "3019\n",
      "<sos> what is wrong with emma ? <eos>\n",
      "3020\n",
      "<sos> all right . <eos>\n",
      "3021\n",
      "<sos> michael ! <eos>\n",
      "3022\n",
      "<sos> oh oh , you lie . <eos>\n",
      "3023\n",
      "<sos> okay , uhm . . . alright , here s the deal . <eos>\n",
      "3024\n",
      "<sos> okay , so it doesn t involve ross or rachel or chandler or joey . but , what about pete ? <eos>\n",
      "3025\n",
      "<sos> all all right ! start it up ! let s go ! <eos>\n",
      "3026\n",
      "<sos> to howard and bernadette , and the house key they never asked me to return . <eos>\n",
      "3027\n",
      "<sos> unless . . . maybe we do it here . i mean , how much can she even be aware of at this age ? if ! supportemptyparas endif <eos>\n",
      "3028\n",
      "<sos> ew . dr . cooper , i ve read everything you ve published . i especially liked your paper on grand unification using string network condensates and was wondering how you determined that three dimensional string nets provided a unified picture of fermions and gauge bosons ? <eos>\n",
      "3029\n",
      "<sos> thanks again for agreeing to do this . <eos>\n",
      "3030\n",
      "<sos> you know what , sheldon , take it . in fact , you can have everything , i really don t care . <eos>\n",
      "3031\n",
      "<sos> we re both frauds . <eos>\n",
      "3032\n",
      "<sos> it s a beautiful country . you d love it . may i join you ? <eos>\n",
      "3033\n",
      "<sos> i m sure you re right , but why ? <eos>\n",
      "3034\n",
      "<sos> i d love it if my dad could come . <eos>\n",
      "3035\n",
      "<sos> it s my house warming present for monica and chandler . <eos>\n",
      "3036\n",
      "<sos> and me . <eos>\n",
      "3037\n",
      "<sos> well , it s very sweet of you to go to all this trouble for leonard s mother . <eos>\n",
      "3038\n",
      "<sos> a little . <eos>\n",
      "3039\n",
      "<sos> did he help you make a decision about the movie ? <eos>\n",
      "3040\n",
      "<sos> that s really nice of you , howard . <eos>\n",
      "3041\n",
      "<sos> yeah , just second . we ll try to keep it down . <eos>\n",
      "3042\n",
      "<sos> you know maybe this is a wake up call , about your whole dating attitude . your in your thirty s and you ve never had a serious relationship and you have never been in a long term relationship , here you go from woman to woman , meaningless\n",
      "3043\n",
      "<sos> thanks for the warning . <eos>\n",
      "3044\n",
      "<sos> maybe . unless they re like two people who have lived in apartments next to each other for years , and then one day they re pushed through a vagina and they meet . <eos>\n",
      "3045\n",
      "<sos> well the divorces don t bother me , i d date him . but , not while he s still married . <eos>\n",
      "3046\n",
      "<sos> you guys , i m sorry , could you please talk a little slower ? <eos>\n",
      "3047\n",
      "<sos> no ! no , we have an emergency . okay ? rachel s coming to london . <eos>\n",
      "3048\n",
      "<sos> what do you mean ? <eos>\n",
      "3049\n",
      "<sos> yeah ? <eos>\n",
      "3050\n",
      "<sos> oh no , let s assume that they can . lois lane is falling , accelerating at an initial rate of feet per second per second . superman swoops down to save her by reaching out two arms of steel . miss lane , who is now travelling at\n",
      "3051\n",
      "<sos> you don t need him . i ll represent you . <eos>\n",
      "3052\n",
      "<sos> and yet you bore his child . neato . <eos>\n",
      "3053\n",
      "<sos> great great and thanks for being so understanding . i mean , i didn t want to make a big deal out of this , you know . you could , uh , put the picture of the famous baby in my room . i mean , if you\n",
      "3054\n",
      "<sos> all right then , so we re all on the same page . yes . <eos>\n",
      "3055\n",
      "<sos> oh ! phoebe , all babies are beautiful ! <eos>\n",
      "3056\n",
      "<sos> did you know my husband has glasses just like that ? <eos>\n",
      "3057\n",
      "<sos> dear ms . buffay . thank you for calling attention to our error . we have credited your account with five hundred dollars . we re sorry for the inconvenience , and hope you ll accept this football phone as our free gift . do you believe this ?\n",
      "3058\n",
      "<sos> ugh , let it go . i have heard that my whole life . every time something upsets me somebody says , let it go , you know , like it s my fault , and it s not okay to feel the way i feel . <eos>\n",
      "3059\n",
      "<sos> okay . sorry . <eos>\n",
      "3060\n",
      "<sos> article , subsection c , if questioned penny may not say that everything is fine if it isn t . other unacceptable responses include , it s nothing , don t worry about it , and , i said it s nothing don t worry about it . <eos>\n",
      "3061\n",
      "<sos> more than pleasant . <eos>\n",
      "3062\n",
      "<sos> hey , look at you , cooper . you re almost halfway to the top . <eos>\n",
      "3063\n",
      "<sos> denied . i need your official answer . <eos>\n",
      "3064\n",
      "<sos> so , do they have a name for a first date with someone you used to go out with ? <eos>\n",
      "3065\n",
      "<sos> we ve actually been working on a prototype for a navigation system we invented . <eos>\n",
      "3066\n",
      "<sos> good luck . <eos>\n",
      "3067\n",
      "<sos> yeah , me , too . <eos>\n",
      "3068\n",
      "<sos> oh yeah ? what are you gonna do ? <eos>\n",
      "3069\n",
      "<sos> geller ! <eos>\n",
      "3070\n",
      "<sos> so we just sit and stare at the screen , waiting for something to happen ? <eos>\n",
      "3071\n",
      "<sos> i didn t know monica had these ! <eos>\n",
      "3072\n",
      "<sos> you told her my experiment was stupid ? <eos>\n",
      "3073\n",
      "<sos> did you say you guys are working on the guidance system tomorrow ? <eos>\n",
      "3074\n",
      "<sos> what re you talkin about ? <eos>\n",
      "3075\n",
      "<sos> what ? <eos>\n",
      "3076\n",
      "<sos> just me and my son . <eos>\n",
      "3077\n",
      "<sos> you know what i m going to do ? i m going to get in my sweats , and eat this in bed ! <eos>\n",
      "3078\n",
      "<sos> okay . <eos>\n",
      "3079\n",
      "<sos> three . <eos>\n",
      "3080\n",
      "<sos> that s true . <eos>\n",
      "3081\n",
      "<sos> so , are you sorry that i told them ? <eos>\n",
      "3082\n",
      "<sos> well , where you going , just put them on . <eos>\n",
      "3083\n",
      "<sos> really ? <eos>\n",
      "3084\n",
      "<sos> am i interrupting ? <eos>\n",
      "3085\n",
      "<sos> he was so good in that movie of macbeth . <eos>\n",
      "3086\n",
      "<sos> like , has leonard betrayed any of his friends recently ? <eos>\n",
      "3087\n",
      "<sos> i know . what are they gonna talk about ? <eos>\n",
      "3088\n",
      "<sos> i know , i know . <eos>\n",
      "3089\n",
      "<sos> let s see what we got here . ohh , y know , fonzie dated triplets . <eos>\n",
      "3090\n",
      "<sos> what i really needed was a blindfold . <eos>\n",
      "3091\n",
      "<sos> forgive my language , but poppycock . <eos>\n",
      "3092\n",
      "<sos> oh yeah , i m jealous . oh gavin , please , please look at my ass . stop looking at my ass ! i mean , i just think you are totally inappropriate , ok ? this is a work environment , she s your subordinate . <eos>\n",
      "3093\n",
      "<sos> is it because she s dating you but was out with that other fellow ? <eos>\n",
      "3094\n",
      "<sos> ugh ! <eos>\n",
      "3095\n",
      "<sos> so , cocoa ? <eos>\n",
      "3096\n",
      "<sos> kites , ho ! <eos>\n",
      "3097\n",
      "<sos> bye bye joey . <eos>\n",
      "3098\n",
      "<sos> can you believe this guy ? <eos>\n",
      "3099\n",
      "<sos> really ? <eos>\n",
      "3100\n",
      "<sos> leonard ? <eos>\n",
      "3101\n",
      "<sos> she d be proud , huh ? <eos>\n",
      "3102\n",
      "<sos> i like that . <eos>\n",
      "3103\n",
      "<sos> what is she talking about ? <eos>\n",
      "3104\n",
      "<sos> you have so few good ideas , leonard . and you re just going to spill the beans in front of an outsider ? <eos>\n",
      "3105\n",
      "<sos> well , if you don t , you re gonna lose priya to some fancy guy in a turban who grew up with kama sutra coloring books . <eos>\n",
      "3106\n",
      "<sos> then why did you say it . <eos>\n",
      "3107\n",
      "<sos> that s not much of a joke . <eos>\n",
      "3108\n",
      "<sos> oh , look at these little bunnies ! <eos>\n",
      "3109\n",
      "<sos> slow down . two hundred . <eos>\n",
      "3110\n",
      "<sos> but that wouldn t be fair to me , it wouldn t be fair to alan it wouldn t be fair to you ! <eos>\n",
      "3111\n",
      "<sos> i know ! <eos>\n",
      "3112\n",
      "<sos> okay . <eos>\n",
      "3113\n",
      "<sos> i took a shot , sue me . <eos>\n",
      "3114\n",
      "<sos> oh , man . i , what an honour to meet you . i m , i m such a fan of tesla and spacex . all your companies . howard wolowitz , caltech . <eos>\n",
      "3115\n",
      "<sos> ross do you realise this is the first time in my life i m doing something i actually care about . this is the first time in my life i m doing something that i m actually good at . i mean . if you don t get that\n",
      "3116\n",
      "<sos> not for you ! <eos>\n",
      "3117\n",
      "<sos> you re welcome . <eos>\n",
      "3118\n",
      "<sos> i m kidding . <eos>\n",
      "3119\n",
      "<sos> ehh . <eos>\n",
      "3120\n",
      "<sos> gosh , amy . i m sensing a little hostility . is it maybe because , like sheldon s work , your sex life is also theoretical ? <eos>\n",
      "3121\n",
      "<sos> okay , but it s valentine s day ! <eos>\n",
      "3122\n",
      "<sos> how the hell did you do that ? <eos>\n",
      "3123\n",
      "<sos> i m sorry , you know , maybe i wasn t being clear . uh , this is our cart . <eos>\n",
      "3124\n",
      "<sos> okay , she would love that ! y know , cause you know all the clean places to eat . <eos>\n",
      "3125\n",
      "<sos> i m just talking about bees . they re on the discovery channel . what are you talking about ? <eos>\n",
      "3126\n",
      "<sos> yeah , this is so good , that i m gonna go enjoy it on the balcony so that i can enjoy the view whilst i enjoy my dessert . <eos>\n",
      "3127\n",
      "<sos> oh my god . <eos>\n",
      "3128\n",
      "<sos> it s gonna be hard to find something you re both equally good at . <eos>\n",
      "3129\n",
      "<sos> okay , so , what s new with you guys . <eos>\n",
      "3130\n",
      "<sos> ya know , you had no right to go out with him . <eos>\n",
      "3131\n",
      "<sos> wow . <eos>\n",
      "3132\n",
      "<sos> oh , that s cute . like it s a real college . <eos>\n",
      "3133\n",
      "<sos> yeah ! why don t you stick around . you can sit right there . <eos>\n",
      "3134\n",
      "<sos> i think it sounds fun . <eos>\n",
      "3135\n",
      "<sos> who are you to decide that ? <eos>\n",
      "3136\n",
      "<sos> fine , i will . <eos>\n",
      "3137\n",
      "<sos> oh , good . <eos>\n",
      "3138\n",
      "<sos> no . . . it s all glued together . <eos>\n",
      "3139\n",
      "<sos> look , um , i think we should talk about what happened on the terrace . <eos>\n",
      "3140\n",
      "<sos> although , i d be lying if i said it wasn t a little bit of a perk . <eos>\n",
      "3141\n",
      "<sos> yeah . <eos>\n",
      "3142\n",
      "<sos> that s intense . <eos>\n",
      "3143\n",
      "<sos> unbelievable . <eos>\n",
      "3144\n",
      "<sos> no no wait wait ! i can t just let you hang up ! just please talk to me . <eos>\n",
      "3145\n",
      "<sos> if you re wondering why i ve been staring through the peephole , i m trying to get a look at this guy who s coming over to penny s . <eos>\n",
      "3146\n",
      "<sos> is dr gablehouser going to be my new daddy ? <eos>\n",
      "3147\n",
      "<sos> that is mark ? <eos>\n",
      "3148\n",
      "<sos> well , maybe it s a contest , y know ? like , collect all five ? <eos>\n",
      "3149\n",
      "<sos> age ? <eos>\n",
      "3150\n",
      "<sos> thank you for agreeing to see me , agent page . <eos>\n",
      "3151\n",
      "<sos> okay , i guess i can hang for a little while . so what are we watching ? sex and the city . <eos>\n",
      "3152\n",
      "<sos> no . they said you weren t believable as a human being . so , you can work on that . <eos>\n",
      "3153\n",
      "<sos> what s going on ? <eos>\n",
      "3154\n",
      "<sos> i bet it s fast . <eos>\n",
      "3155\n",
      "<sos> aaaa aw ! <eos>\n",
      "3156\n",
      "<sos> no no , i i just , i liked them so much that i went out and bought some for myself . <eos>\n",
      "3157\n",
      "<sos> that s so great . <eos>\n",
      "3158\n",
      "<sos> eh , maybe it s your voice . i m gonna see if i can get james earl jones to do it in post . <eos>\n",
      "3159\n",
      "<sos> well hello ! so , when are we gettin back out on the water matey ? <eos>\n",
      "3160\n",
      "<sos> joey , this is die hard again . <eos>\n",
      "3161\n",
      "<sos> okay , here we go . . . <eos>\n",
      "3162\n",
      "<sos> well , look it s not my fault if you re too uptight to appreciate the male form in all it s glory . <eos>\n",
      "3163\n",
      "<sos> no , no , no , no , let s talk about it . i m the one who s made all the effort in this relationship since day one . please tell me what more i could do ? <eos>\n",
      "3164\n",
      "<sos> i think i m gonna cry ! <eos>\n",
      "3165\n",
      "<sos> thanks . yeah , i figure if i wear these in my scenes at least i won t get spit in the eyes , y know ? <eos>\n",
      "3166\n",
      "<sos> janice is gonna go away now . <eos>\n",
      "3167\n",
      "<sos> oh my god ! are you serious ? ! <eos>\n",
      "3168\n",
      "<sos> yeah , it s weird . even though he didn t want to give the lecture in the first place , being rejected by those students really hit him hard . <eos>\n",
      "3169\n",
      "<sos> hehehehey , isn t that the guy who used to wear your hat ? <eos>\n",
      "3170\n",
      "<sos> yeah . <eos>\n",
      "3171\n",
      "<sos> hello . <eos>\n",
      "3172\n",
      "<sos> yeah , me , too . triple digits , i m not gonna lie , feels pretty good . <eos>\n",
      "3173\n",
      "<sos> we ll discuss it , in the morning ! <eos>\n",
      "3174\n",
      "<sos> oh , uh , hi , penny . yes , please . <eos>\n",
      "3175\n",
      "<sos> hi ! i m so sorry to barge in on your valentine s , but i had to get away from all the yelling . mona is dumping ross . <eos>\n",
      "3176\n",
      "<sos> okay . what do you watch on thanksgiving ? <eos>\n",
      "3177\n",
      "<sos> yeah ! <eos>\n",
      "3178\n",
      "<sos> i came to talk to you about howard . <eos>\n",
      "3179\n",
      "<sos> i m at the westin . <eos>\n",
      "3180\n",
      "<sos> hey . want to join us ? <eos>\n",
      "3181\n",
      "<sos> i walk up to the large chest , bury my face in it and go blublublublublublublublu <eos>\n",
      "3182\n",
      "<sos> but what if uh and i m not saying she will be but <eos>\n",
      "3183\n",
      "<sos> you okay in there , bestie ? <eos>\n",
      "3184\n",
      "<sos> oh great ! what , you brought joey ? <eos>\n",
      "3185\n",
      "<sos> fine . <eos>\n",
      "3186\n",
      "<sos> cherry , baby <eos>\n",
      "3187\n",
      "<sos> oh yeah ? hi , ken adams , nice to meet you . <eos>\n",
      "3188\n",
      "<sos> well , it s a limited edition . they only made , of these bad boys . <eos>\n",
      "3189\n",
      "<sos> i know you do . me too . so what now ? <eos>\n",
      "3190\n",
      "<sos> listen . listen . smelly cat , smelly cat , what are they feeding you ? <eos>\n",
      "3191\n",
      "<sos> that s enough , sheldon . <eos>\n",
      "3192\n",
      "<sos> yeah , you want some ? <eos>\n",
      "3193\n",
      "<sos> yeah , it s totally meant to be . tell him who you originally wanted to hook up with that night . <eos>\n",
      "3194\n",
      "<sos> excuse me , the word is polish . see ? small p . <eos>\n",
      "3195\n",
      "<sos> that sounds really cool . <eos>\n",
      "3196\n",
      "<sos> you ve got to pick a pocket or two . . . . . . . . . . <eos>\n",
      "3197\n",
      "<sos> what ? <eos>\n",
      "3198\n",
      "<sos> well , no , no , wait , wait , wait . all right , i gotta go . just listen . promise me , that you will wait a minute before you call her . <eos>\n",
      "3199\n",
      "<sos> get married . <eos>\n"
     ]
    }
   ],
   "source": [
    "for i in range(3000,3200):\n",
    "    print(i)\n",
    "    convert_to_word(dia_test[i],tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> you ve spoiled everything ! it s like a nightmare ! my friends and family are out there ! how can i face them ? ! how can you do this to me ? ! <eos>\n",
      "<sos> hey , no matter what happens with ross and emily , we still get cake right ? <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> well , i don t think so . <eos>\n",
      "<sos> well , i don t know . <eos>\n",
      "<sos> well , i don t think so . i mean , you know , i think you re gonna be able to be able to be a little uncomfortable . <eos>\n",
      "addressee:13\n",
      "speaker:0\n"
     ]
    }
   ],
   "source": [
    "convert_to_word(dia_test[idx2],tokenizer)\n",
    "convert_to_word(res_test[idx2],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx2],sid_test[idx2],beam_size=3)\n",
    "print(\"addressee:{}\".format(aid_test[idx2]))\n",
    "print(\"speaker:{}\".format(sid_test[idx2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> you ve spoiled everything ! it s like a nightmare ! my friends and family are out there ! how can i face them ? ! how can you do this to me ? ! <eos>\n",
      "<sos> hey , no matter what happens with ross and emily , we still get cake right ? <eos>\n",
      "RESPONSE:\n",
      "4 Finished sentence:\n",
      "<sos> hey ! <eos>\n",
      "<sos> okay , you re a big deal ! <eos>\n",
      "<sos> okay , you re a big deal . <eos>\n",
      "<sos> <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(1)\n",
    "convert_to_word(dia_test[idx2],tokenizer)\n",
    "convert_to_word(res_test[idx2],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx2],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> you ve spoiled everything ! it s like a nightmare ! my friends and family are out there ! how can i face them ? ! how can you do this to me ? ! <eos>\n",
      "<sos> hey , no matter what happens with ross and emily , we still get cake right ? <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> what ? ! <eos>\n",
      "<sos> what ? <eos>\n",
      "<sos> what are you doing ? ! <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(2)\n",
    "convert_to_word(dia_test[idx2],tokenizer)\n",
    "convert_to_word(res_test[idx2],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx2],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> you ve spoiled everything ! it s like a nightmare ! my friends and family are out there ! how can i face them ? ! how can you do this to me ? ! <eos>\n",
      "<sos> hey , no matter what happens with ross and emily , we still get cake right ? <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> well , i mean , i mean , i mean , i mean , i mean , you re the only one who s gonna be able to get married . <eos>\n",
      "<sos> well , i mean , i mean , it s not like i ve been thinking about it . <eos>\n",
      "<sos> well , i mean , i mean , i mean , i mean , i mean , you re the only one who s gonna be able to get married , and i just have to be the one who s been married to . <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(3)\n",
    "convert_to_word(dia_test[idx2],tokenizer)\n",
    "convert_to_word(res_test[idx2],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx2],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> you ve spoiled everything ! it s like a nightmare ! my friends and family are out there ! how can i face them ? ! how can you do this to me ? ! <eos>\n",
      "<sos> hey , no matter what happens with ross and emily , we still get cake right ? <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> what ? ! <eos>\n",
      "<sos> what ? <eos>\n",
      "<sos> what ? ! what ? ! <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(4)\n",
    "convert_to_word(dia_test[idx2],tokenizer)\n",
    "convert_to_word(res_test[idx2],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx2],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> you ve spoiled everything ! it s like a nightmare ! my friends and family are out there ! how can i face them ? ! how can you do this to me ? ! <eos>\n",
      "<sos> hey , no matter what happens with ross and emily , we still get cake right ? <eos>\n",
      "RESPONSE:\n",
      "3 Finished sentence:\n",
      "<sos> i know . <eos>\n",
      "<sos> oh , i m sorry . <eos>\n",
      "<sos> i m sorry . <eos>\n"
     ]
    }
   ],
   "source": [
    "speaker = tf.convert_to_tensor(5)\n",
    "convert_to_word(dia_test[idx2],tokenizer)\n",
    "convert_to_word(res_test[idx2],tokenizer)\n",
    "print(\"RESPONSE:\")\n",
    "response(train_nn,dia_test[idx2],speaker,beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
